{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1209c1bb",
   "metadata": {},
   "source": [
    "# Image classification - redux"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635c9165",
   "metadata": {},
   "source": [
    "We load the same data set as last week (only using 3-channel images instead of 1-channel images) to classify lungs as \"normal\" or with \"pneumonia\". As before, we augment the dataset, using an `ImageDataGenerator`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70729a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3b5da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten,  GlobalAveragePooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb70f880",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['NORMAL','PNEUMONIA']\n",
    "img_size = 192\n",
    "def load_data(data_dir):\n",
    "    x_data = [] \n",
    "    y_data = []\n",
    "    for label in labels: \n",
    "        path = os.path.dirname(os.getcwd())\n",
    "        path = os.path.join(path+'/Week 7/'+data_dir, label)\n",
    "        class_num = labels.index(label)\n",
    "        for img in [f for f in os.listdir(path) if not f.startswith('.')]:\n",
    "            try:\n",
    "                img_arr = cv2.imread(os.path.join(path, img))\n",
    "                resized_arr = cv2.resize(img_arr, (img_size, img_size))\n",
    "                x_data.append(resized_arr)\n",
    "                y_data.append(class_num)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "    x = np.stack(x_data,axis=0).reshape(-1,img_size,img_size,3)\n",
    "    x = x / 255\n",
    "    y = np.array(y_data,dtype='float32')    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b97282",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = load_data('chest_xray/train')\n",
    "x_val, y_val = load_data('chest_xray/val')\n",
    "x_test, y_test = load_data('chest_xray/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbb348f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5\n",
    "plt.figure(figsize=(2*n, 4))\n",
    "for i in range(n):\n",
    "    # display normal\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_train[np.where(y_train==0.0)[0][i]],cmap='gray')\n",
    "    plt.title(\"normal\")\n",
    "    #plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display pneumonia\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(x_train[np.where(y_train==1.0)[0][i]],cmap='gray')\n",
    "    plt.title(\"pneumonia\")\n",
    "    #plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c51522",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        rotation_range = 30,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.2, # Randomly zoom image \n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip = True)  # randomly flip images horizontally\n",
    "\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae10ac35",
   "metadata": {},
   "source": [
    "## 1. Loading an existing model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef00457b",
   "metadata": {},
   "source": [
    "Instead of creating our own model, we load `MobileNet` as a basemodel. As you can see in the summary, this is quite the deep CNN! We load the model without its top layer, which is a fully connected layer (`include_top=False`). This is because we want to adapt the network for our specific prediction task.\n",
    "\n",
    "When loading an existing model from TensorFlow, we can usually specify what parameters (`weights`) we want. Here, we are getting weights that were learned when training the model on the ImageNet (`'imagenet'`) dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f04c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.mobilenet.MobileNet(input_shape=(img_size,img_size,3),\n",
    "                                            include_top=False,\n",
    "                                            weights='imagenet')\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7f0b10",
   "metadata": {},
   "source": [
    "Usually, we keep the weights of the original model as they are. That is, when training with our data, we only adjust the weights of our own layers, that we will add. The easiest is to set the whole original model to be \"untrainable\", but you could also do this layer-by-layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0a8b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf43101b",
   "metadata": {},
   "source": [
    "Let's take another look at the summary. Focus specifically on the numbers of trainable and non-trainable parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75111878",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847abed2",
   "metadata": {},
   "source": [
    "Our model will now combine the `MobileNet` model with three additional layers:\n",
    "1. a `GlobalAveragePooling2D` layer (which summarizes the first two dimensions into a single value)\n",
    "1. a (hidden) `Dense` layer with 8 neurons and a `'relu'` activation function, as well as\n",
    "1. a `Dense` output layer with `'sigmoid'` activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed56fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    base_model,\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(8, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a72efb",
   "metadata": {},
   "source": [
    "We can compile the model as usual, specifying `loss`, `optimizer`, and `metrics`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2678cfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.005),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d0177a",
   "metadata": {},
   "source": [
    "And we can summarize it. In the summary, the `MobileNet` in total is given as one layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a020574b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9885b9",
   "metadata": {},
   "source": [
    "## 2. Training the new top layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a67df1",
   "metadata": {},
   "source": [
    "We are now ready to get training. Note that, even if we fixed the parameters of the `MobileNet`, forward- and back-propagation now take a lot longer, since our neural network has gotten a lot deeper. Hence, so does the training process (even though it is still much much faster than when training the entire network from scratch)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba318e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_red_callback = ReduceLROnPlateau(monitor='val_accuracy', patience = 2, verbose=1,factor=0.3, min_lr=1e-6)\n",
    "log = model.fit(datagen.flow(x_train,y_train, batch_size = 32),\n",
    "                epochs=12,\n",
    "                validation_data=datagen.flow(x_val,y_val),\n",
    "                callbacks=[lr_red_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b01ca57",
   "metadata": {},
   "source": [
    "## 3. Evaluating the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc8c906",
   "metadata": {},
   "source": [
    "We can now evaluate the model. We went from approx. 90% accuracy on the test set to 92% accuracy. That is quite the difference, when it comes to diagnosing medical images correctly. And this is without any fine-tuning, and using \"only\" a relatively simple neural network compared to the state of the art."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36074f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4024db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adl_env",
   "language": "python",
   "name": "adl_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
