{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d256e085",
   "metadata": {},
   "source": [
    "# Tutorial 2 - Hyperparameter tuning and autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e20eb1",
   "metadata": {},
   "source": [
    "Welcome to Tutorial 2. We will learn how to run a hyperparameter tuning operation, before we dive into programming an autoencoder. Parts of the notebook are based on the TensorFlow tutorials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffc385a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import datetime\n",
    "import os\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea6989f",
   "metadata": {},
   "source": [
    "# 1. Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3f0ea8",
   "metadata": {},
   "source": [
    "We will look at two ways to tune hyperparameters. The first relies on TensorBoard and makes things quite visual. It's also relatively intuitive, but doesn't have as much functionality as the second way of using Keras Tuner."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e281128f",
   "metadata": {},
   "source": [
    "## 1.1 Using HParams and TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130eb03b",
   "metadata": {},
   "source": [
    "We will use the California housing price dataset, that you should be familiar with by now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4ae63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = fetch_california_housing()\n",
    "\n",
    "X_train, X_other, y_train, y_other = train_test_split(housing['data'], housing['target'], train_size=0.7, random_state=461)\n",
    "X_test, X_valid, y_test, y_valid = train_test_split(X_other, y_other, train_size = 0.5, random_state=391)\n",
    "print(X_train.shape)\n",
    "print(X_valid.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100dc1c4",
   "metadata": {},
   "source": [
    "HParams works together with TensorBoard, so we load the TensorBoard extension into the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16aa4bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6c6bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57ab374",
   "metadata": {},
   "source": [
    "The following command deletes the log folder and may be useful for cleaning up. But be careful not to delete the things you still want to keep:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb120d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rm -rf ./logs/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ccf26c0",
   "metadata": {},
   "source": [
    "We start by defining the parameters to tune over. We will tune the learning rate, the choice of optimizer, the dropout rate, and the number of hidden units per layer. We will stay fixed with two hidden layers, however.\n",
    "\n",
    "Using HParams, we define the parameters, as well as the interval over which we may vary them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69413c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "HP_LEARNING_RATE = hp.HParam('learning_rate', hp.RealInterval(0.001,1.0))\n",
    "HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['adam', 'sgd']))\n",
    "HP_DROPOUT = hp.HParam('dropout', hp.RealInterval(0.1, 0.3))\n",
    "HP_NUM_UNITS = hp.HParam('num_units', hp.Discrete(range(3,21)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd9334d",
   "metadata": {},
   "source": [
    "We also need to define the metrics to measure. We will only care about the mean squared error in our case, since we are performing a regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c385bdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "METRIC_MSE = 'mean_squared_error'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859b0d63",
   "metadata": {},
   "source": [
    "Once we have set up our parameters and metrics, we write those into our folder with the logs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fa226b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.summary.create_file_writer('logs/hparam_tuning').as_default():\n",
    "    hp.hparams_config(hparams=[HP_LEARNING_RATE, HP_OPTIMIZER, HP_DROPOUT, HP_NUM_UNITS],\n",
    "                      metrics = [hp.Metric(METRIC_MSE, display_name='MSE')])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430d45de",
   "metadata": {},
   "source": [
    "Next, we define a function that creates and trains a model, and evaluates it on the test set. This function will get a dictionary `hparams`, that contains the different parameter choices. Hence, the way the model is build is kept variable.\n",
    "\n",
    "The function also logs the choice of parameters and the output of our function (the mse), in order to display both in TensorBoard. For this purpose, we give it the current directory where the relevant information should be kept, `run_dir`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eaf7b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_model(hparams, run_dir):\n",
    "    \n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dropout(hparams[HP_DROPOUT]),\n",
    "        tf.keras.layers.Dense(hparams[HP_NUM_UNITS], activation=\"relu\"),\n",
    "        tf.keras.layers.Dropout(hparams[HP_DROPOUT]),\n",
    "        tf.keras.layers.Dense(hparams[HP_NUM_UNITS], activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(1)])\n",
    "    \n",
    "    if hparams[HP_OPTIMIZER] == 'sgd':\n",
    "        # Note that exploding gradients can be a big problem when running regressions, especially under SGD\n",
    "        # Hence, we use \"gradient clipping\" with parameter alpha, which means that the gradients are manually kept between -1 and 1\n",
    "        # This is of course another hyperparameter that we might tune!\n",
    "        optimizer = tf.keras.optimizers.SGD(learning_rate=hparams[HP_LEARNING_RATE],clipvalue=1)\n",
    "    elif hparams[HP_OPTIMIZER] == 'adam':\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=hparams[HP_LEARNING_RATE])\n",
    "        \n",
    "    model.compile(  optimizer=optimizer,\n",
    "                    loss='mean_squared_error')\n",
    "\n",
    "    model.fit(X_train, y_train, epochs=10)\n",
    "    mse = model.evaluate(X_valid, y_valid)\n",
    "    \n",
    "    with tf.summary.create_file_writer(run_dir).as_default():\n",
    "        hp.hparams(hparams)\n",
    "        tf.summary.scalar(METRIC_MSE, mse, step=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62c12d9",
   "metadata": {},
   "source": [
    "Finally, we run a few different choices of parameters. Remember to choose parameters randomly! It is fine to sample the `dropout_rate`, `num_units` and `optimizer` at uniformly, but keep in mind the scaling issue when it comes to the `learning_rate`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a856921",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_sessions = 5\n",
    "\n",
    "for session in range(total_sessions):\n",
    "    \n",
    "    # Create hyperparameters randomly\n",
    "    dropout_rate = HP_DROPOUT.domain.sample_uniform()\n",
    "    num_units = HP_NUM_UNITS.domain.sample_uniform()\n",
    "    optimizer = HP_OPTIMIZER.domain.sample_uniform()\n",
    "    \n",
    "    r = -3*np.random.rand()\n",
    "    learning_rate = 10.0**r\n",
    "    \n",
    "    # Create a dictionary of hyperparameters\n",
    "    hparams = { HP_LEARNING_RATE: learning_rate,\n",
    "                HP_OPTIMIZER: optimizer,\n",
    "                HP_DROPOUT: dropout_rate,\n",
    "                HP_NUM_UNITS: num_units}\n",
    "    \n",
    "    # train the model with the chosen parameters\n",
    "    run_name = \"run-%d\" % session\n",
    "    print('--- Starting trial: %s' % run_name)\n",
    "    print({h.name: hparams[h] for h in hparams})\n",
    "    train_test_model(hparams,'logs/hparam_tuning/' + run_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81bcda3c",
   "metadata": {},
   "source": [
    "Finally, we display the runs using TensorBoard. If you are lucky, it is enough to call\n",
    "```\n",
    "%tensorboard --logdir logs\n",
    "```\n",
    "Otherwise, you might have to specify the path to the TensorBoard binary, such as here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3281f8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TENSORBOARD_BINARY'] = '/Users/philippe/anaconda3/envs/adl_env/bin/tensorboard'\n",
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee55886f",
   "metadata": {},
   "source": [
    "Once you have chosen a model that you like based on the hyperparameter search, how do you proceed?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd6a03d",
   "metadata": {},
   "source": [
    "## 1.2 Using the Keras Tuner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2308da52",
   "metadata": {},
   "source": [
    "We will next use the Keras Tuner, an toolbox within Keras to tune hyperparameters. You may need to install this first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475ff17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install keras-tuner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be353c1a",
   "metadata": {},
   "source": [
    "Once we have installed Keras Tuner, we can import it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99461e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94c47c3",
   "metadata": {},
   "source": [
    "With Keras Tuner, we create again a function that builds a model. This time, however, the function does not contain the actual model fitting and evaluation, only the model building and compilation.\n",
    "\n",
    "We start simple, with a function that builds a model with an arbitrary number of units per hidden layer. Instead of pre-specifying the parameters, the Keras Tuner now generates them, based on the `hp` input to the function. We want an integer value for `num_units`, between 3 and 20. Hence, we can use \n",
    "```\n",
    "num_units = hp.Int('num_units', min_value = ..., max_value=...)\n",
    "```\n",
    "where the `min_value` and `max_value` are filled appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c910105",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(hp):    \n",
    "    num_units = hp.Int('num_units', min_value = 3, max_value=20)\n",
    "    \n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(num_units, activation=\"relu\"),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(num_units, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(1)])\n",
    "    \n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "        \n",
    "    model.compile(  optimizer=optimizer,\n",
    "                    loss='mean_squared_error')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933cc487",
   "metadata": {},
   "source": [
    "Once we have defined the function to build the model, we can create a Keras Tuner object. Here, we have to decide how we want to do the tuning.\n",
    "\n",
    "We could use `kt.RandomSearch` to consider different random combinations of hyperparameters, as we have before. But the real benefit of using a hyperparameter tuning framework like Keras Tuner comes from the ability to do better. In particular, we can use the following tuners that don't just look randomly at different sets of hyperparameters, but choose sets of hyperparameters that make sense to explore based on what the tuner has seen so far:\n",
    "- `Hyperband`\n",
    "- `BayesianOptimization`\n",
    "- `Sklearn`\n",
    "\n",
    "We will use Hyperband here. If you want to know exactly how it works, you can find [the relevant paper here](https://arxiv.org/pdf/1603.06560.pdf).\n",
    "\n",
    "The code below generates a `Hyperband` tuner. We need to specify\n",
    "- `max_epochs`, that is the maximum number of epochs that any trial is allowed to take (the tuner will usually only use a part of these epochs and stop early if the trial seems hopeless compared to other trials)\n",
    "- `factor` (if we don't specify this, it defaults to 3, which is usually fine), which has to do with the reduction of epochs across trials. It goes beyond the scope of the course, but if you want to know more, you can find all the information in the paper\n",
    "- `directory`, where our log is stored\n",
    "- `project_name`, the sub-directory to store our log\n",
    "\n",
    "Note that we don't specify the number of trials! This is based on how the algorithm works and will be roughly\n",
    "```\n",
    "max_epochs * log(max_epochs) / log(factor)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4727fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.Hyperband(train_model,\n",
    "                     objective='val_loss',\n",
    "                     max_epochs=10,\n",
    "                     factor=3,\n",
    "                     directory='logs2',\n",
    "                     project_name='kt_tutorial_1')                     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9053ab44",
   "metadata": {},
   "source": [
    "Note that the tuner won't run if the folder `'directory/project_name'` has already been filled. In that case, you might want to clear it out as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af0b9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "rm -rf ./logs2/kt_tutorial_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a943832",
   "metadata": {},
   "source": [
    "Next, we can run the tuner with the `search` function. This takes the same inputs as when you `fit` a single model. Only that it will now generate parameters based on the Hyperband algorithm.\n",
    "\n",
    "\n",
    "When the tuner runs, you can see the current statistics, as well as the statistics of the best hyperparameter set found so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5446d340",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search(X_train,y_train,validation_data=(X_valid,y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f6cccf",
   "metadata": {},
   "source": [
    "Once you are done, you can take a look at the best hyperparameters found. You can index them like a dictionary (based on the name you gave before):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fb8486",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hps = tuner.get_best_hyperparameters()[0]\n",
    "best_hps['num_units']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0a221d",
   "metadata": {},
   "source": [
    "We can also now directly build a model that uses the best hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd97759",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = tuner.hypermodel.build(best_hps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86242d02",
   "metadata": {},
   "source": [
    "This is a fresh model that we still have to train (the hyperparameters have been chosen, but the parameters (weights and biases) don't even exist yet (verify this, for example, with `best_model.layers[1].get_weights()`)\n",
    "\n",
    "Hence, we now train the model as usual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8256ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.fit(X_train, y_train,\n",
    "               epochs=30,\n",
    "               validation_data=(X_valid,y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08217a82",
   "metadata": {},
   "source": [
    "Once we are done with training, we can evaluate the model on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90bf67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2177cf12",
   "metadata": {},
   "source": [
    "### Tuning more parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1602a263",
   "metadata": {},
   "source": [
    "Let's make things a bit more interesting. Create again the `train_model(hp)` function, but this time, we vary all the hyperparameters that we varied before. In particular:\n",
    "- vary the `num_units`, as before\n",
    "- vary the `dropout_rate`. This is not an integer value, but a float, but otherwise things are like before. Hence, you want to use `hp.Float('dropout_rate', min_value = ..., max_value=...)` with the right values\n",
    "- vary the `optimizer`. Here, we choose from a set of two different ones, so we can use `hp.Choice('optimizer', values=[....])`. Make sure to specify the values from which you are choosing and then set the right optimizer with an `if...else` block, as we did earlier\n",
    "- vary the `learning_rate`. This is a float again, but remember that we want a log-scale. Here, we can implement this quite easily with `hp.Float('learning_rate', min_value = ..., max_value=..., sampling='log')` (and, of course, again with the right minimum and maximum values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f21419",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(hp):    \n",
    "    num_units = hp.Int('num_units', min_value = 3, max_value=20) \n",
    "    dropout_rate = hp.Float('dropout_rate', min_value = 0.1, max_value=0.3) \n",
    "    optim_algo = hp.Choice('optimizer', values=['sgd','adam']) \n",
    "    learning_rate = hp.Float('learning_rate', min_value = 0.001, max_value=1, sampling='log') \n",
    "    \n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dropout(dropout_rate),\n",
    "        tf.keras.layers.Dense(num_units, activation=\"relu\"),\n",
    "        tf.keras.layers.Dropout(dropout_rate),\n",
    "        tf.keras.layers.Dense(num_units, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(1)])\n",
    "    \n",
    "    if optim_algo == 'sgd':\n",
    "        optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate,clipvalue=1)\n",
    "    elif optim_algo == 'adam':\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "            \n",
    "    model.compile(  optimizer=optimizer,\n",
    "                    loss='mean_squared_error')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3fa713",
   "metadata": {},
   "source": [
    "Once you have specified your model, we can again generate the `Hyperband` tuner object and search through the space of hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2f6200",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.Hyperband(train_model,\n",
    "                     objective='val_loss',\n",
    "                     max_epochs=10,\n",
    "                     factor=3,\n",
    "                     directory='logs2',\n",
    "                     project_name='kt_tutorial_2')\n",
    "tuner.search(X_train, y_train, validation_data=(X_valid,y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c8fa3e",
   "metadata": {},
   "source": [
    "Once done, take a look at the optimal parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80531db",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hps = tuner.get_best_hyperparameters()[0]\n",
    "print(\"Best learning rate: \" + str(best_hps['learning_rate']))\n",
    "print(\"Best optimizer: \" + str(best_hps['optimizer']))\n",
    "print(\"Best dropout rate: \" + str(best_hps['dropout_rate']))\n",
    "print(\"Best number of hidden units: \" + str(best_hps['num_units']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b62d6db",
   "metadata": {},
   "source": [
    "Again, we can build a fresh model using these hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7c2e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = tuner.hypermodel.build(best_hps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e814270",
   "metadata": {},
   "source": [
    "This time, we won't just train the model, we will also add in an `EarlyStopping` callback. Can you create a callback `early_stopping_cb` using `tf.keras.callbacks.EarlyStopping(...)`, with `patience=10` and `restor_best_weights=True`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fed8877",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669dda3b",
   "metadata": {},
   "source": [
    "Now, train the best model, using also an early stop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af53b2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.fit(X_train, y_train,\n",
    "               epochs=30,\n",
    "               validation_data=(X_valid,y_valid),\n",
    "               callbacks=[early_stopping_cb])\n",
    "print(\"MSE on test set: \" + str(best_model.evaluate(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c118f3",
   "metadata": {},
   "source": [
    "# 2. Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d9d5f6",
   "metadata": {},
   "source": [
    "We will build autoencoders. First, we create a simple autoencoder to compress data, then we will create another one that allows to denoise images! In your assignment, you will also build an autoencoder to detect anomalies - quite the versatile tool, right?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa56240",
   "metadata": {},
   "source": [
    "## 2.1 A basic autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5739afc",
   "metadata": {},
   "source": [
    "We use the previous `fashion_mnist` dataset that you should be familiar with by now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1048366",
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "(X_other, y_other), (X_test, y_test) = fashion_mnist.load_data()\n",
    "X_other = X_other / 255.\n",
    "X_test = X_test / 255.\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_other, y_other, train_size = 50000, random_state=152)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0481616a",
   "metadata": {},
   "source": [
    "An autoencoder consists of two parts: the encoder (with less and less neurons per layer) and the decoder (with more and more neurons per layer). You don't have to, but it usually makes sense to define the encoder and the decoder separately. Let's start with the encoder. We will create an encoder that flattens the inputs, but only uses one hidden layer (with 64 inputs):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e4a985",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28,28)),\n",
    "    tf.keras.layers.Dense(64, activation=\"relu\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0aafb6",
   "metadata": {},
   "source": [
    "Keep in mind that our inputs have $28\\times 28 = 784$ dimensions, while the input layer only has $64$ \"dimensions\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bb97a9",
   "metadata": {},
   "source": [
    "We can now define a decoder (with a single layer). Keep in mind that we want to return an image, so we have to reshape our output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d06b479",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(784, activation=\"sigmoid\"),\n",
    "    tf.keras.layers.Reshape((28,28))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817ea0f1",
   "metadata": {},
   "source": [
    "The autoencoder now simply takes the encoding layers and the decoding layers and puts them together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955e7410",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = tf.keras.Sequential([encoder,decoder])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33201eae",
   "metadata": {},
   "source": [
    "Let's take a look at our autoencoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e44c410",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23026d03",
   "metadata": {},
   "source": [
    "This doesn't tell us much, since it doesn't break up the encoder and decoder. However, we can look at individual summaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89799da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3443a26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f107f0a6",
   "metadata": {},
   "source": [
    "The output has the same shape as our original inputs - good!\n",
    "We also need to make sure that the output is even able to recreate the input. Consider that each image-pixel is a value between 0 and 1 (because we normalized it like this). Recall that `'sigmoid'` can take values between 0 and 1, so it seems ideal for our purposes!\n",
    "\n",
    "Let's now compile our model. For autoencoders, we usually use the `'mean_squared_error'` as a loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08780222",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb8e98a",
   "metadata": {},
   "source": [
    "After compiling, we can train the model. The important part is that we train the model to recreate the input. So what should our \"y\" be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf90c8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.fit(x=X_train, y=X_train,\n",
    "                epochs=10,\n",
    "                validation_data=(X_valid, X_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8125c141",
   "metadata": {},
   "source": [
    "Now that we have trained the model, we can encode and decode our test data (we can either use the `autoencoder` directly to get the recreated data, or we can do so in two steps: first get the encoding, then use the encoding to recreate the data. We usually use the second approach in case we might want to better understand the encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74e1d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_imgs = encoder(X_test).numpy()\n",
    "decoded_imgs = decoder(encoded_imgs).numpy()\n",
    "print(X_test.shape)\n",
    "print(encoded_imgs.shape)\n",
    "print(decoded_imgs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43bea54a",
   "metadata": {},
   "source": [
    "Let's look at some examples; both the original data and the recreated data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e74a07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5\n",
    "plt.figure(figsize=(2*n, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(X_test[i])\n",
    "    plt.title(\"original\")\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i])\n",
    "    plt.title(\"reconstructed\")\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d755f72",
   "metadata": {},
   "source": [
    "Keep in mind that we only use $\\frac{64}{28*28} \\approx 8\\%$ of the features in the encoding, so this is quite the powerful result!\n",
    "\n",
    "What do you observe when you decrease the number of layers in the encoding even further?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521e81db",
   "metadata": {},
   "source": [
    "## 2.2 Denoising data using an autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c1a6ba",
   "metadata": {},
   "source": [
    "We will now train an autoencoder to denoise images (you know, like the clich√© geek in action thrillers). So let's create some noisy data - we add some normally distributed (\"Gaussian\") noise to the data. We also \"clip\" the data, to make sure that the pixel values are still between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c6b6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = 0.2\n",
    "\n",
    "X_train_noisy = X_train + noise * tf.random.normal(shape=X_train.shape) \n",
    "X_valid_noisy = X_valid + noise * tf.random.normal(shape=X_valid.shape) \n",
    "X_test_noisy = X_test + noise * tf.random.normal(shape=X_test.shape) \n",
    "\n",
    "X_train_noisy = tf.clip_by_value(X_train_noisy, clip_value_min=0., clip_value_max=1.)\n",
    "X_valid_noisy = tf.clip_by_value(X_valid_noisy, clip_value_min=0., clip_value_max=1.)\n",
    "X_test_noisy = tf.clip_by_value(X_test_noisy, clip_value_min=0., clip_value_max=1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb413b32",
   "metadata": {},
   "source": [
    "Let's take a look at some images and their noisy version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c81088",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5\n",
    "plt.figure(figsize=(2*n, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(X_test[i])\n",
    "    plt.title(\"original\")\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(X_test_noisy[i])\n",
    "    plt.title(\"original + noise\")\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25ef206",
   "metadata": {},
   "source": [
    "Of course, you can increase or decrease the noise by simply changing the `noise` parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4bc6e9",
   "metadata": {},
   "source": [
    "Let's now create an autoencoder. This will use convolutional layers - but don't worry, you don't need to know in detail what they do, we will get back to them in the next class.\n",
    "\n",
    "Start by creating an `encoder`, as before. However, instead of flattening the input and then using one `Dense` layer, we now use three different layers:\n",
    "1. a `Reshape` layer, with `tf.keras.layers.Reshape((28,28,1), input_shape=(28,28))` (this is because convolutional layers work with 3 dimensions, so we convert our matrices into 3-dimensional arrays, where the last dimension simply has size 1 - so basically still a matrix)\n",
    "1. a `Conv2D` layer, with `tf.keras.layers.Conv2D(16, (3, 3), activation='relu', padding='same', strides=2)`\n",
    "1. a `Conv2D` layer, with `tf.keras.layers.Conv2D(8, (3, 3), activation='relu', padding='same', strides=2)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de893923",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = tf.keras.Sequential([\n",
    "    tf.keras.layers.Reshape((28,28,1), input_shape=(28,28)),\n",
    "    tf.keras.layers.Conv2D(16, (3, 3), activation='relu', padding='same', strides=2),\n",
    "    tf.keras.layers.Conv2D(8, (3, 3), activation='relu', padding='same', strides=2)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d77e484",
   "metadata": {},
   "source": [
    "Next, create a `decoder`. Again, this is simply a `Sequential` model, that basically builds a symmetric version of the `encoder`. This time, we need three layers:\n",
    "1. a `Conv2DTranspose` layer (basically inverting a convolutional layer), with `tf.keras.layers.Conv2DTranspose(8, kernel_size=3, strides=2, activation='relu', padding='same')`\n",
    "1. another `Conv2DTranspose` layer, with `tf.keras.layers.Conv2DTranspose(16, kernel_size=3, strides=2, activation='relu', padding='same')`\n",
    "1. a `Conv2D` layer, that allows use to recreate the output, with `tf.keras.layers.Conv2D(1, kernel_size=(3, 3), activation='sigmoid', padding='same')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefe8792",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2DTranspose(8, kernel_size=3, strides=2, activation='relu', padding='same'),\n",
    "    tf.keras.layers.Conv2DTranspose(16, kernel_size=3, strides=2, activation='relu', padding='same'),\n",
    "    tf.keras.layers.Conv2D(1, kernel_size=(3, 3), activation='sigmoid', padding='same')])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3da8a3d",
   "metadata": {},
   "source": [
    "Do you see why the output is able to recreate the input? What is the critical ingredient here?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a86eb8c",
   "metadata": {},
   "source": [
    "We can now combine everything into an `autoencoder`, exactly as we did before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d024321d",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = tf.keras.Sequential([encoder,decoder]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d0666e",
   "metadata": {},
   "source": [
    "Next, take a look at the summary of the `encoder`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c93d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5b18c1",
   "metadata": {},
   "source": [
    "Compare the dimensions of the original input with the dimension of the encoding: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d44ba39",
   "metadata": {},
   "outputs": [],
   "source": [
    "28*28*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c17700b",
   "metadata": {},
   "outputs": [],
   "source": [
    "7*7*8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a4242b",
   "metadata": {},
   "source": [
    "Let's also take a look at the decoding process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f59285d",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f88c0aa",
   "metadata": {},
   "source": [
    "Next, compile the `autoencoder`. As before, we use the `'mean_squared_error'` as a loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8ef19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37800d91",
   "metadata": {},
   "source": [
    "Finally, we need to train our `autoencoder`. Remember that we are taking the noisy image and then trying to predict the original one (**not** the noisy one) - so make sure to set the right \"y\" values for both training and validation.\n",
    "\n",
    "Then, run the training for 10 epochs - this might take a bit, so it's a good time for a break."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78cf8404",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.fit(x=X_train_noisy, y=X_train,\n",
    "                epochs=10,\n",
    "                validation_data=(X_valid_noisy, X_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63c62e4",
   "metadata": {},
   "source": [
    "Let's create again the encodings of the (noisy) test images, as well as the decoded version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5bf17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_imgs = encoder(X_test_noisy).numpy()\n",
    "decoded_imgs = decoder(encoded_imgs).numpy()\n",
    "\n",
    "print(X_test.shape)\n",
    "print(encoded_imgs.shape)\n",
    "print(decoded_imgs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c46f19",
   "metadata": {},
   "source": [
    "We can plot all three: original images, noisy versions, and decoded original images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc830a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5\n",
    "plt.figure(figsize=(2*n,6))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(3, n, i + 1)\n",
    "    plt.title(\"original\")\n",
    "    plt.imshow(tf.squeeze(X_test[i]))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    \n",
    "    # display original + noise\n",
    "    bx = plt.subplot(3, n, i + n + 1)\n",
    "    plt.title(\"original + noise\")\n",
    "    plt.imshow(tf.squeeze(X_test_noisy[i]))\n",
    "    plt.gray()\n",
    "    bx.get_xaxis().set_visible(False)\n",
    "    bx.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    cx = plt.subplot(3, n, i + 2*n + 1)\n",
    "    plt.title(\"reconstructed\")\n",
    "    plt.imshow(tf.squeeze(decoded_imgs[i]))\n",
    "    plt.gray()\n",
    "    cx.get_xaxis().set_visible(False)\n",
    "    cx.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff660055",
   "metadata": {},
   "source": [
    "Not at the level of an action thriller yet, but pretty good for a very basic neural network without much tuning!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adl_env",
   "language": "python",
   "name": "adl_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
