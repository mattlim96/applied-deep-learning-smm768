{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b404e681",
   "metadata": {},
   "source": [
    "# 1. A first look at image classification with ConvNets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d07578d",
   "metadata": {},
   "source": [
    "We will take a look at using convolutional layers inside a neural network. In particular, we will work on classifying X-ray images of lungs as normal or having pneumonia.\n",
    "This part of the notebook is based in parts on a Kaggle tutorial by [Madhav Mathur](https://www.kaggle.com/madz2000/pneumonia-detection-using-cnn-92-6-accuracy).\n",
    "\n",
    "If you haven't done so, you will need to install opencv with the following line (note that the import uses `cv2` instead of the full name)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e801e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b193131",
   "metadata": {},
   "source": [
    "We have a number of imports to do. You should be familiar with all of those, except `cv`, `Model`, `Conv2D`, `MaxPool2D`, `ImageDataGenerator`, and `ReduceLROnPlateau` which we introduce throughout the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb266cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPool2D, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956890e4",
   "metadata": {},
   "source": [
    "## 1.1 Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b72cd4c",
   "metadata": {},
   "source": [
    "We use the following dataset, also available on Kaggle: [Kermany, Zhang, Goldbaum (2018)\"Labeled Optical Coherence Tomography (OCT) and Chest X-Ray Images for Classification\"](https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia). Note that we have somewhat shifted around images from the test to the validation set (the original validation set only contains 16 images).\n",
    "\n",
    "The function below takes any of the subdirectories (`'train'`, `'val'`, `'test'`), it then\n",
    "1. Reads in the images (interpreted as being in grayscale), using `cv2`\n",
    "1. Resizes them according tour our pre-defined `img_size`\n",
    "1. Reshapes the images to be three-dimension (with one channel instead of three, as we have grayscale images, not RGB images)\n",
    "1. Normalizes the pixel values to the 0-1 interval\n",
    "1. Returns the image data and the corresponding label as 0 (normal) or 1 (pneumonia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b2c803",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['NORMAL','PNEUMONIA']\n",
    "img_size = 200\n",
    "def load_data(data_dir):\n",
    "    x_data = [] \n",
    "    y_data = []\n",
    "    for label in labels: \n",
    "        path = os.path.join(data_dir, label)\n",
    "        class_num = labels.index(label)\n",
    "        for img in [f for f in os.listdir(path) if not f.startswith('.')]:\n",
    "            try:\n",
    "                img_arr = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
    "                resized_arr = cv2.resize(img_arr, (img_size, img_size)) # reshape images to preferred size\n",
    "                x_data.append(resized_arr)\n",
    "                y_data.append(class_num)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "    x = np.stack(x_data,axis=0).reshape(-1,img_size,img_size,1) # reshape images to 4-dim array\n",
    "    x = x / 255 # normalize data to 0-1\n",
    "    y = np.array(y_data,dtype='float32')    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30c6a6a",
   "metadata": {},
   "source": [
    "We call the previous function in order to load the three data sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101d847a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = load_data('chest_xray/train')\n",
    "x_val, y_val = load_data('chest_xray/val')\n",
    "x_test, y_test = load_data('chest_xray/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40d4680",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape)\n",
    "print(x_val.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f0e541",
   "metadata": {},
   "source": [
    "Let's take a look at the labels on the training data. it seems that there are many more images with pneumonia than without, but the order of magnitude is similar, so this should be okay:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6e96df",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist((y_train[y_train==0.0],y_train[y_train==1.0]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ecf76ff",
   "metadata": {},
   "source": [
    "We can also take a look at some examples with and without pneumonia:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8710bcb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5\n",
    "plt.figure(figsize=(2*n, 4))\n",
    "for i in range(n):\n",
    "    # display normal\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_train[np.where(y_train==0.0)[0][i]],cmap='gray')\n",
    "    plt.title(\"normal\")\n",
    "    #plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display pneumonia\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(x_train[np.where(y_train==1.0)[0][i]],cmap='gray')\n",
    "    plt.title(\"pneumonia\")\n",
    "    #plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24a8457",
   "metadata": {},
   "source": [
    "## 1.2 Data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454b33ad",
   "metadata": {},
   "source": [
    "In order to avoid overfitting, aside from regularization, we can artifically extend our dataset. This is commonly done with image data, especially when we have only few datapoints. The idea is to alter the training data with small transformations to produce different images every time our fitting process calls up the next batch. In this example, we will:\n",
    "\n",
    "1. Randomly rotate by up to 30 degrees\n",
    "1. Randomly zoom by up to 20% some\n",
    "1. Randomly shift images horizontally by up to 10% of their width\n",
    "1. Randomly shift images vertically by up to 10% of their height\n",
    "1. Randomly flip images horizontally.\n",
    "\n",
    "Note that we are not creating a fixed number of data points. Instead, we create an `ImageDataGenerator`, which is fit to our original training data, and generates new images by randomly applying the different operations mentioned above. It keeps giving out images as long as we are fitting the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2415d4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        rotation_range = 30,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.2, # Randomly zoom image \n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip = True)  # randomly flip images horizontally\n",
    "\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55174a85",
   "metadata": {},
   "source": [
    "## 1.3 A standard feed-forward network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0eecbf0",
   "metadata": {},
   "source": [
    "Let's start by creating a standard feed-forward network with 3 hidden layers and 100 neurons each, as well as a sigmoid output layer (why?) We will use the `Adam` optimizer with a pre-specified learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2535e594",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Flatten(input_shape=(img_size,img_size,1)),\n",
    "    \n",
    "    Dense(100, activation=\"relu\"),\n",
    "    \n",
    "    Dense(100, activation=\"relu\"),\n",
    "    \n",
    "    Dense(100, activation=\"relu\"),\n",
    "    \n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "model.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=tf.keras.optimizers.Adam(5e-4),\n",
    "              metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50dc43ed",
   "metadata": {},
   "source": [
    "We next fit the model. We will use a new callback, the `ReduceLROnPlateau`, which observes a certain metric and if this metric no longer improves (considering a certain patience), reduces the learning rate by a given factor. Very similar to the learning rate schedules we have seen before, just some different mechanics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f16a3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_red_callback = ReduceLROnPlateau(monitor='val_accuracy', patience = 2, verbose=1,factor=0.3, min_lr=1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f02cbe",
   "metadata": {},
   "source": [
    "Otherwise, this is the usual process, just that we are not directly inputting our training data, but instead we are providing data from the `ImagaDataGenerator`. We specify a `batch_size` as for the usual fitting process, but this also tells the generator how many images to return at any time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbc6ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "log = model.fit(datagen.flow(x_train,y_train, batch_size = 32),\n",
    "                epochs=12,\n",
    "                validation_data=datagen.flow(x_val,y_val),\n",
    "                callbacks=[lr_red_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc3bfd4",
   "metadata": {},
   "source": [
    "Let's see how we are doing in terms of loss and accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da85e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_plot(log):\n",
    "    plt.plot(log.history['accuracy'],label = \"training accuracy\",color='green')\n",
    "    plt.plot(log.history['loss'],label = \"training loss\",color='darkgreen')\n",
    "    plt.plot(log.history['val_accuracy'], label = \"validation accuracy\",color='grey')\n",
    "    plt.plot(log.history['val_loss'], label = \"validation loss\",color='darkblue')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "create_plot(log)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee37090",
   "metadata": {},
   "source": [
    "The validation accuracy is not fantastic. With a bit of fine-tuning (dropout, batch normalization, a better learning rate, some callbacks), you can reach an accuracy of 90% or so. Not fantastic, but a good start."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e9ea8c",
   "metadata": {},
   "source": [
    "Once we are fine with our model, we will evaluate it on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111207c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbb0aa9",
   "metadata": {},
   "source": [
    "Let's also take a look at the confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01384bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test)\n",
    "predictions = predictions.reshape(1,-1)[0]\n",
    "predictions = (predictions > 0.5)\n",
    "confusion_matrix(y_test,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b02c7aa",
   "metadata": {},
   "source": [
    "## 1.4 A convolutional neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828b6507",
   "metadata": {},
   "source": [
    "We will now use convolution and max-pooling layers. As is common, we start with a few (large) channels, then decrease the width and height of our layers, but make them increasingly deep.\n",
    "\n",
    "At the end, we add a dense layer, as well as the sigmoid output from before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e814603",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv = Sequential([\n",
    "    Conv2D(32, kernel_size=(3,3), strides=(2,2), padding='same', activation=\"relu\", input_shape=(img_size,img_size,1)),\n",
    "    MaxPool2D((2,2), strides=(2,2), padding='same'),\n",
    "    \n",
    "    Conv2D(64, kernel_size=(3,3), strides=(2,2), padding='same', activation=\"relu\"),\n",
    "    MaxPool2D((2,2), strides=(2,2), padding='same'),\n",
    "    \n",
    "    Flatten(),\n",
    "    Dense(100, activation=\"relu\"),\n",
    "    \n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "model_conv.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=tf.keras.optimizers.Adam(5e-4),\n",
    "              metrics=[\"accuracy\"])\n",
    "model_conv.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b4899e",
   "metadata": {},
   "source": [
    "Training proceeds exactly as before. Note that, even though we have many less parameters, it tends to take much longer to train convlutional neural networks. Be ready to wait a bit (and this is a very simple network, still!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06de3e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_red_callback = ReduceLROnPlateau(monitor='val_accuracy', patience = 2, verbose=1,factor=0.3, min_lr=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f0309a",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_conv = model_conv.fit(datagen.flow(x_train,y_train, batch_size = 32),\n",
    "                            epochs=12,\n",
    "                            validation_data=datagen.flow(x_val,y_val),\n",
    "                            callbacks=[lr_red_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d59a285",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_plot(log_conv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da7cc68",
   "metadata": {},
   "source": [
    "The accuracy on the validation set looks somewhat better (and also less variable). There is still a lot to be done. Again, dropout and batch normalization can help, as well as adding more layers. The network presented in the Kaggle notebook linked above gets to around 93% accuracy. With much bigger networks, 96-99% should be possible - but we will only use such networks pre-trained, or we could be spending quite some time training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff491f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6385f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model_conv.predict(x_test)\n",
    "predictions = predictions.reshape(1,-1)[0]\n",
    "predictions = (predictions > 0.5)\n",
    "confusion_matrix(y_test,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69914b9b",
   "metadata": {},
   "source": [
    "### DISCUSSION AND TO DOS\n",
    "\n",
    "Can you do better? Try adding Dropout and Batch-Normalization layers.\n",
    "\n",
    "Would you say it is easier or harder to fine-tune a CNN or a normal feed-forward network? Why?\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64ecf49",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "# 2. Non-sequential models with the Functional API\n",
    "\n",
    "We will now take a first peek at running non-sequential models. An example application is object detection (we need to predict classes **and** bounding boxes). But there are many other sceneraios where you want to tweak your model non-sequentially, e.g., to introduce skip connection (see next week's video).\n",
    "\n",
    "Here, we will train a model that predicts both normal/pneumonia lungs, as well as the average value of the input pixel images (not too hard to predict, but this is really just to show you how we can use the Functional API of TensorFlow).\n",
    "\n",
    "Let's first create the secondary y's:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012d0702",
   "metadata": {},
   "outputs": [],
   "source": [
    "y2_train = np.mean(x_train,axis=(1,2,3))\n",
    "y2_val = np.mean(x_val,axis=(1,2,3))\n",
    "y2_test = np.mean(x_test,axis=(1,2,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c2aebe",
   "metadata": {},
   "source": [
    "The Functional API works very similarly to the Sequential API. But instead of having a list of layers, we just create layers and connect them arbitrarily. To do so, we just specify the previous layer that is supposed to flow into the current layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211bd78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_input = Input(shape=(img_size, img_size, 1)) # We start with an input layer (we could have multiple inputs, too!)\n",
    "\n",
    "x = Conv2D(32, kernel_size=(3,3), strides=(2,2), padding='same', activation=\"relu\")(model_input) # We then create a Convolutional layer, which takes the input layer as an input\n",
    "x = MaxPool2D((2,2), strides=(2,2), padding='same')(x) # Next, we create a Pooling layer that takes the convolutional layer as its input\n",
    "    \n",
    "x = Conv2D(64, kernel_size=(3,3), strides=(2,2), padding='same', activation=\"relu\")(x) # As before\n",
    "x = MaxPool2D((2,2), strides=(2,2), padding='same')(x) # As before\n",
    "     \n",
    "x = Flatten()(x)  # As before\n",
    "x = Dense(100,activation=\"relu\")(x)  # As before\n",
    "\n",
    "model_output_1 = Dense(1, activation=\"sigmoid\", name = 'output_1')(x) # Now we create an output layer that predicts the class (normal / pneumonia). It uses whatever comes out of the network so far\n",
    "model_output_2 = Dense(1, activation=\"sigmoid\", name = 'output_2')(x) # We create a second output layer. Note that this does not connect to the other output layer, but directly to the last hidden layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2843b38e",
   "metadata": {},
   "source": [
    "We have all the same layers defined as before, just with a second output layer. Note that we give a specific name to our output-layers, so we can reference them later!\n",
    "\n",
    "We combine our layers in a model. We just have ot specify what our inputs are and what our outputs are. The remaining layers are added based on the structure above!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38f1708",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_func = Model(inputs = [model_input], outputs=[model_output_1, model_output_2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b0fd1e",
   "metadata": {},
   "source": [
    "See for yourself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4733c629",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_func.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fb6219",
   "metadata": {},
   "source": [
    "Let's now compile our non-sequential model. We need to define our losses and metrics for each of our outputs! This is why we gave the output layers specific names, so we can use this here. The rest is as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905f600b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_func.compile(loss={'output_1':'binary_crossentropy',\n",
    "                         'output_2':'mean_squared_error'},\n",
    "                   loss_weights = [1,0.01],\n",
    "                   metrics = {'output_1':'accuracy',\n",
    "                             'output_2':'mean_squared_error'},\n",
    "                   optimizer=tf.keras.optimizers.Adam(5e-4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4f8cfa",
   "metadata": {},
   "source": [
    "Similar for fitting the model: We have to make clear that there are two different y values that need to be predicted. We will run the model only for a few epochs, to see how it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9f67d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_func = model_func.fit(x=x_train,y=[y_train,y2_train],\n",
    "                            epochs=3,\n",
    "                            validation_data=(x_val,[y_val,y2_val]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33700c7b",
   "metadata": {},
   "source": [
    "As always, we can evaluate the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5bbb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_func.evaluate(x_test, [y_test,y2_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e532dec0",
   "metadata": {},
   "source": [
    "And we can make predictions. We just have to note that two outputs are being predicted, the labels and the average values. But we can simply use list-indices to get the right ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f51f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model_func.predict(x_test)\n",
    "predictions_label = predictions[0].reshape(1,-1)[0]\n",
    "predictions_label = (predictions_label > 0.5)\n",
    "confusion_matrix(y_test,predictions_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682ee5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_avg = predictions[1]\n",
    "predictions_avg"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adl_env",
   "language": "python",
   "name": "adl_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
